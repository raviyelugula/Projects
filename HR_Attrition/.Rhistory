data_set = read.csv('HR_Employee_Attrition_Data.csv', header = T)
sapply(data_set,class)
table(sapply(data_set,class))
factor_feildIDs=which(sapply(data_set, class) == "factor")
integer_feildIDs=which(sapply(data_set, class) == "integer")
library(caTools)
set.seed(123)
split_vector = sample.split(data_set$Attrition,SplitRatio = 0.7)
Dev_data = subset(data_set, split_vector==T)
HoldOut_data = subset(data_set, split_vector ==F)
require(ggplot2)
for( i in factor_feildIDs){
name = paste('D:/GL/Assignment/',names(Dev_data[i]),'.png', sep = '')
png(filename = name, width = 800, height = 600, units = 'px')
print(ggplot( Dev_data,
aes(x=Dev_data[,i],
fill =Dev_data$Attrition))+
xlab(names(Dev_data[i]))+
ylab('Frequency')+
geom_bar(position = 'dodge')+
guides(fill = guide_legend('Attrition')))
dev.off()
print.noquote(names(Dev_data[i]))
print.noquote(summary(Dev_data[,i]))
}
for( i in factor_feildIDs){
name = paste(names(Dev_data[i]),'.png', sep = '')
png(filename = name, width = 800, height = 600, units = 'px')
print(ggplot( Dev_data,
aes(x=Dev_data[,i],
fill =Dev_data$Attrition))+
xlab(names(Dev_data[i]))+
ylab('Frequency')+
geom_bar(position = 'dodge')+
guides(fill = guide_legend('Attrition')))
dev.off()
print.noquote(names(Dev_data[i]))
print.noquote(summary(Dev_data[,i]))
}
for(i in factor_feildIDs){
if(length(levels(Dev_data[,i]))==1){
print.noquote(paste0(names(Dev_data[i]),' has only 1 category and its feild id is ',i))
}
}
for( i in integer_feildIDs){
if(max(Dev_data[,i])==min(Dev_data[,i])){
print.noquote(paste0('All the values of ',names(Dev_data[i]),' are : ',
max(Dev_data[,i]),' and its ID is : ',i ))
}
}
require(gclus)
install.packages('gclus')
require(gclus)
cor_int_data1 = Dev_data[c(head(integer_feildIDs,13))]
cor_int_data2 = Dev_data[c(tail(integer_feildIDs,13))]
png(filename = 'D:/GL/Assignment/Correlation_1.png', width = 1600, height = 1200, units = 'px')
png(filename = 'Correlation_1.png', width = 1600, height = 1200, units = 'px')
cpairs(data = cor_int_data1,
panel.colors = dmat.color(abs(cor(cor_int_data1))),
gap =0.5)
dev.off()
png(filename = 'D:/GL/Assignment/Correlation_2.png', width = 1600, height = 1200, units = 'px')
png(filename = 'Correlation_2.png', width = 1600, height = 1200, units = 'px')
cpairs(data = cor_int_data2,
panel.colors = dmat.color(abs(cor(cor_int_data2))),
gap =0.5)
dev.off()
rm(list = c("integer_feildIDs","factor_feildIDs","cor_int_data1",
"cor_int_data2","i","name"))
Missing_data_Check <- function(data_set){
NA_Count = sapply(data_set,function(y) sum(length(which(is.na(y)))))
Null_Count = sapply(data_set,function(y) sum(length(which(is.null(y)))))
Length0_Count = sapply(data_set,function(y) sum(length(which(length(y)==0))))
Empty_Count = sapply(data_set,function(y) sum(length(which(y==''))))
Total_NonData = NA_Count+Null_Count+Length0_Count+Empty_Count
return( Total_NonData )
}
if(length(which(Missing_data_Check(Dev_data)>0))==0){
print("No Missing data")
}else{
which(Missing_data_Check(Dev_data)>0)
}
Dev_data = Dev_data[,-c(9,22,27)] # removing 'Over18','EmployeeCount','StandardHours'
names(Dev_data)
library(randomForest)
set.seed(123)
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  5000,
mtry =  6,
nodesize = 40)
RF_model
plot(RF_model, main = "High number of trees vs OOB error")
set.seed(123)
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  500,
mtry =  6,
nodesize = 40)
RF_model
plot(RF_model, main = "Adjusted tree number vs OOB error")
set.seed(123)
tuned_RF_model = tuneRF(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
mtryStart = 2,
stepFactor = 1.5,
improve = 0.001,
ntreeTry = 500,
nodesize = 40,
doBest = T, trace = T, plot = T,importance = T)
tuned_RF_model #tune_RF - 19
library(caret)
set.seed(123)
grid_RF_tune = train(x = Dev_data[-2],
y = Dev_data$Attrition,
method = 'rf')
grid_RF_tune #gridsearch gives 16
test = numeric()
rm(test)
dev_acc = numeric()
nodesize_value = numeric()
holdout_acc = numeric()
j = 1
for (i in seq(from = 1, to = 90 , by = 3)){
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  500,
mtry =  19,
nodesize = i)
if(RF_model$confusion[1]!=2058 & RF_model$confusion[2]!=2058){
dev_acc[j] = (RF_model$confusion[1]+RF_model$confusion[4])/2058
nodesize_value[j] = i
holdout_prediction = predict(RF_model, newdata = HoldOut_data, type ='class')
table = table(HoldOut_data$Attrition,holdout_prediction)
holdout_acc[j] = (table[1]+table[4])/882
j = j+1
}
}
nodesize_df = data.frame(x=nodesize_value,y1=dev_acc,y2=holdout_acc)
names(nodesize_df)
sapply(nodesize_df,class)
library(ggplot2)
png('\node_size.png',width = 800, height = 600, units = 'px')
png('node_size.png',width = 800, height = 600, units = 'px')
ggplot() +
geom_line(data = nodesize_df,
aes(nodesize_df$x,nodesize_df$y1),col = 'red')+
geom_line(data = nodesize_df,
aes(nodesize_df$x,nodesize_df$y2),col = 'green')+
xlab('node size')+
ylab('accuracy')+
ggtitle('ntree is 500 & mtry is 6')
dev.off()
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  500,
mtry =  6,
nodesize = 20)
RF_model
rm(list = c("nodesize_df","dev_acc","holdout_prediction",
"i","j","nodesize_value","RF_model","table","split_vector"))
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  500,
mtry =  6,
nodesize = 20)
RF_model
require(caret)
set.seed(123)
fold = createFolds(Dev_data$Attrition, k=10)
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-fold,]
test_fold = Dev_data[fold,]
temp_model = randomForest(x = train_fold[-2],
y = train_fold$Attrition,
data_set = train_fold,
ntree =  500,
mtry =  6,
nodesize = 20)
test_pred = predict(temp_model,test_fold[-2],type = 'class')
table = table(test_fold,test_pred)
acc = (table[1]+table[4])/nrow(test_fold)
return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = randomForest(x = train_fold[-2],
y = train_fold$Attrition,
data_set = train_fold,
ntree =  500,
mtry =  6,
nodesize = 20)
test_pred = predict(temp_model,test_fold[-2],type = 'class')
table = table(test_fold,test_pred)
acc = (table[1]+table[4])/nrow(test_fold)
return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = svm(formula = Attrition ~ .,
data = train_fold,
type = 'C-classification',
kernel = 'radial')
# temp_model = randomForest(x = train_fold[-2],
#                           y = train_fold$Attrition,
#                           data_set = train_fold,
#                           ntree =  500,
#                           mtry =  6,
#                           nodesize = 20)
test_pred = predict(temp_model,test_fold[-2],type = 'class')
table = table(test_fold,test_pred)
acc = (table[1]+table[4])/nrow(test_fold)
return(acc)
})
require(e1071)
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = svm(formula = Attrition ~ .,
data = train_fold,
type = 'C-classification',
kernel = 'radial')
# temp_model = randomForest(x = train_fold[-2],
#                           y = train_fold$Attrition,
#                           data_set = train_fold,
#                           ntree =  500,
#                           mtry =  6,
#                           nodesize = 20)
test_pred = predict(temp_model,test_fold[-2],type = 'class')
table = table(test_fold,test_pred)
acc = (table[1]+table[4])/nrow(test_fold)
return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = svm(formula = Attrition ~ .,
data = train_fold,
type = 'C-classification',
kernel = 'radial')
# temp_model = randomForest(x = train_fold[-2],
#                           y = train_fold$Attrition,
#                           data_set = train_fold,
#                           ntree =  500,
#                           mtry =  6,
#                           nodesize = 20)
test_pred = predict(temp_model,test_fold[-2],type = 'class')
table = table(test_fold,test_pred)
acc = (table[1]+table[4])/nrow(test_fold)
return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = svm(formula = Attrition ~ .,
data = train_fold,
type = 'C-classification',
kernel = 'radial')
# temp_model = randomForest(x = train_fold[-2],
#                           y = train_fold$Attrition,
#                           data_set = train_fold,
#                           ntree =  500,
#                           mtry =  6,
#                           nodesize = 20)
test_pred = predict(temp_model,newdata=test_fold[-2])
tableAcc = table(test_fold,test_pred)
acc = (tableAcc[1]+tableAcc[4])/nrow(test_fold)
return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = svm(formula = Attrition ~ .,
data = train_fold,
type = 'C-classification',
kernel = 'radial')
# temp_model = randomForest(x = train_fold[-2],
#                           y = train_fold$Attrition,
#                           data_set = train_fold,
#                           ntree =  500,
#                           mtry =  6,
#                           nodesize = 20)
test_pred = predict(temp_model,newdata=test_fold[-2])
tableAcc = table(test_fold,test_pred)
acc = (tableAcc[1]+tableAcc[4])/nrow(test_fold)
return(acc)
})
fold[1]
x=fold[1]
train_fold = Dev_data[-x,]
class(fold)
Fold01
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
# temp_model = svm(formula = Attrition ~ .,
#                 data = train_fold,
#                 type = 'C-classification',
#                 kernel = 'radial')
# # temp_model = randomForest(x = train_fold[-2],
# #                           y = train_fold$Attrition,
# #                           data_set = train_fold,
# #                           ntree =  500,
# #                           mtry =  6,
# #                           nodesize = 20)
# test_pred = predict(temp_model,newdata=test_fold[-2])
# tableAcc = table(test_fold,test_pred)
# acc = (tableAcc[1]+tableAcc[4])/nrow(test_fold)
# return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = svm(formula = Attrition ~ .,
data = train_fold,
type = 'C-classification',
kernel = 'radial')
# # temp_model = randomForest(x = train_fold[-2],
# #                           y = train_fold$Attrition,
# #                           data_set = train_fold,
# #                           ntree =  500,
# #                           mtry =  6,
# #                           nodesize = 20)
# test_pred = predict(temp_model,newdata=test_fold[-2])
# tableAcc = table(test_fold,test_pred)
# acc = (tableAcc[1]+tableAcc[4])/nrow(test_fold)
# return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = svm(formula = Attrition ~ .,
data = train_fold,
type = 'C-classification',
kernel = 'radial')
# temp_model = randomForest(x = train_fold[-2],
#                           y = train_fold$Attrition,
#                           data_set = train_fold,
#                           ntree =  500,
#                           mtry =  6,
#                           nodesize = 20)
test_pred = predict(temp_model,newdata=test_fold[-2])
tableAcc = table(test_fold,test_pred)
# acc = (tableAcc[1]+tableAcc[4])/nrow(test_fold)
# return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = svm(formula = Attrition ~ .,
data = train_fold,
type = 'C-classification',
kernel = 'radial')
# temp_model = randomForest(x = train_fold[-2],
#                           y = train_fold$Attrition,
#                           data_set = train_fold,
#                           ntree =  500,
#                           mtry =  6,
#                           nodesize = 20)
test_pred = predict(temp_model,newdata=test_fold)
tableAcc = table(test_fold,test_pred)
# acc = (tableAcc[1]+tableAcc[4])/nrow(test_fold)
# return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = svm(formula = Attrition ~ .,
data = train_fold,
type = 'C-classification',
kernel = 'radial')
# temp_model = randomForest(x = train_fold[-2],
#                           y = train_fold$Attrition,
#                           data_set = train_fold,
#                           ntree =  500,
#                           mtry =  6,
#                           nodesize = 20)
test_pred = predict(temp_model,newdata=test_fold[-2])
# tableAcc = table(test_fold,test_pred)
# acc = (tableAcc[1]+tableAcc[4])/nrow(test_fold)
# return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = svm(formula = Attrition ~ .,
data = train_fold,
type = 'C-classification',
kernel = 'radial')
# temp_model = randomForest(x = train_fold[-2],
#                           y = train_fold$Attrition,
#                           data_set = train_fold,
#                           ntree =  500,
#                           mtry =  6,
#                           nodesize = 20)
test_pred = predict(temp_model,newdata=test_fold[-2])
tableAcc = table(test_fold,test_pred)
# acc = (tableAcc[1]+tableAcc[4])/nrow(test_fold)
# return(acc)
})
acc_vector = lapply(fold, function(x){
train_fold = Dev_data[-x,]
test_fold = Dev_data[x,]
temp_model = randomForest(x = train_fold[-2],
y = train_fold$Attrition,
data_set = train_fold,
ntree =  500,
mtry =  6,
nodesize = 20)
test_pred = predict(temp_model,newdata=test_fold[-2])
tableAcc = table(test_fold$Attrition,test_pred)
acc = (tableAcc[1]+tableAcc[4])/nrow(test_fold)
return(acc)
})
k_fold_dev_acc = mean(as.numeric(acc_vector))
k_fold_dev_acc
RF_Prediction = predict(RF_model, HoldOut_data,type = 'class')
table(HoldOut_data$Attrition,RF_Prediction)
87/882
87/882 -1
(87/882)-1
