data_set = read.csv('HR_Employee_Attrition_Data.csv', header = T)
table(sapply(data_set,class))
factor_feildIDs=which(sapply(data_set, class) == "factor")
integer_feildIDs=which(sapply(data_set, class) == "integer")
library(caTools)
set.seed(123)
split_vector = sample.split(data_set$Attrition,SplitRatio = 0.7)
Dev_Original = subset(data_set, split_vector==T)
HoldOut_Original = subset(data_set, split_vector ==F)
Dev_data = Dev_Original
HoldOut_data = HoldOut_Original
require(ggplot2)
for( i in factor_feildIDs){
name = paste(names(Dev_data[i]),'.png', sep = '')
png(filename = name, width = 800, height = 600, units = 'px')
print(ggplot( Dev_data,
aes(x=Dev_data[,i],
fill =Dev_data$Attrition))+
xlab(names(Dev_data[i]))+
ylab('Frequency')+
geom_bar(position = 'dodge')+
guides(fill = guide_legend('Attrition')))
dev.off()
print.noquote(names(Dev_data[i]))
print.noquote(summary(Dev_data[,i]))
}
for(i in factor_feildIDs){
if(length(levels(Dev_data[,i]))==1){
print.noquote(paste0(names(Dev_data[i]),' has only 1 category and its feild id is ',i))
}
}
for( i in integer_feildIDs){
if(max(Dev_data[,i])==min(Dev_data[,i])){
print.noquote(paste0('All the values of ',names(Dev_data[i]),' are : ',
max(Dev_data[,i]),' and its ID is : ',i ))
}
}
for(i in factor_feildIDs){
if(length(levels(Dev_data[,i]))==1){
print.noquote(paste0(names(Dev_data[i]),' has only 1 category and its field id is ',i))
}
}
Missing_data_Check <- function(data_set){
NA_Count = sapply(data_set,function(y) sum(length(which(is.na(y)))))
Null_Count = sapply(data_set,function(y) sum(length(which(is.null(y)))))
Length0_Count = sapply(data_set,function(y) sum(length(which(length(y)==0))))
Empty_Count = sapply(data_set,function(y) sum(length(which(y==''))))
Total_NonData = NA_Count+Null_Count+Length0_Count+Empty_Count
return( Total_NonData )
}
if(length(which(Missing_data_Check(Dev_data)>0))==0){
print("No Missing data")
}else{
which(Missing_data_Check(Dev_data)>0)
}
Dev_data = Dev_data[,-c(9,10,22,27)] # removing 'Over18','EmployeeCount','StandardHours','Employeenumber'
HoldOut_data = HoldOut_data[,-c(9,10,22,27)]
library(randomForest)
set.seed(123)
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  5000,  # large number because we want to build as many trees as possible
mtry =  6,
nodesize = 40)
RF_model
plot(RF_model, main = "Adjusted tree number vs OOB error")
tuned_RF_model #tune_RF - 19
grid_RF_tune #gridsearch gives 16
temp_dev_acc = numeric()
temp_nodesize = numeric()
temp_hold_acc = numeric()
j = 1
for (i in seq(from = 1, to = 90 , by = 3)){
set.seed(123)
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  500,
mtry =  19,
nodesize = i)
if(RF_model$confusion[1]!=2058 & RF_model$confusion[2]!=2058){
temp_dev_acc[j] = (RF_model$confusion[1]+RF_model$confusion[4])/2058
temp_nodesize[j] = i
holdout_prediction = predict(RF_model, newdata = HoldOut_data, type ='class')
table = table(HoldOut_data$Attrition,holdout_prediction)
temp_hold_acc[j] = (table[1]+table[4])/882
j = j+1
}
}
nodesize_df = data.frame(x=temp_nodesize,y1=temp_dev_acc,y2=temp_hold_acc)
library(ggplot2)
png('node_size.png',width = 800, height = 600, units = 'px')
ggplot() +
geom_line(data = nodesize_df,
aes(nodesize_df$x,nodesize_df$y1),col = 'red')+
# geom_line(data = nodesize_df,
#           aes(nodesize_df$x,nodesize_df$y2),col = 'green')+
xlab('node size')+
ylab('accuracy')+
ggtitle('ntree is 500 & mtry is 6')
dev.off()
png('node_size.png',width = 800, height = 600, units = 'px')
ggplot() +
geom_line(data = nodesize_df,
aes(nodesize_df$x,nodesize_df$y1),col = 'red')+
# geom_line(data = nodesize_df,
#           aes(nodesize_df$x,nodesize_df$y2),col = 'green')+
xlab('node size')+
ylab('accuracy')+
ggtitle('ntree is 500 & mtry is 6')
dev.off()
ggplot() +
geom_line(data = nodesize_df,
aes(nodesize_df$x,nodesize_df$y1),col = 'red')+
# geom_line(data = nodesize_df,
#           aes(nodesize_df$x,nodesize_df$y2),col = 'green')+
xlab('node size')+
ylab('accuracy')+
ggtitle('ntree is 500 & mtry is 6')
ggplot() +
geom_line(data = nodesize_df,
aes(nodesize_df$x,nodesize_df$y1),col = 'red')+
# geom_line(data = nodesize_df,
#           aes(nodesize_df$x,nodesize_df$y2),col = 'green')+
xlab('node size')+
ylab('accuracy')+
ggtitle('ntree is 500 & mtry is 19')
set.seed(123)
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  500,
mtry =  19,
nodesize = 2)
RF_model
plot(RF_model)
rm(list = c("nodesize_df","holdout_prediction","i","j",
"temp_nodesize","temp_dev_acc","temp_hold_acc","table"))
Dev_Original$RF_Prob = predict(RF_model,newdata = Dev_data, type='prob')
Dev_Original$RF_Prob =Dev_Original$RF_Prob[,2]
Holdout_prediction_Prob = predict(RF_model,newdata = HoldOut_data, type='prob')
Holdout_prediction_class =predict(RF_model,newdata = HoldOut_data, type='class')
HoldOut_data$RF_prob =Holdout_prediction_Prob[,2]
HoldOut_data$RF_class = Holdout_prediction_class
HoldOut_Original$RF_prob = HoldOut_data$RF_prob
HoldOut_Original$RF_Class = Holdout_prediction_class
Confusion_Matrix_RF=addmargins(table(actual = HoldOut_data$Attrition, Prediction = HoldOut_data$RF_class))
Confusion_Matrix_RF
Accuracy_RF=(Confusion_Matrix_RF[1]+Confusion_Matrix_RF[5])/Confusion_Matrix_RF[9]*100
Accuracy_RF #97.05 %
Confusion_Matrix_RF
Accuracy_RF
Integer_dataset= data_set[,c(integer_feildIDs,factor_feildIDs)]
Integer_dataset = Integer_dataset[,-c(5,6,18,34)] # removing 'Over18','EmployeeCount','EmployeeNumber','StandardHours'
summary(Integer_dataset$BusinessTravel)
str(Integer_dataset$BusinessTravel)
Integer_dataset$BusinessTravel
str(Integer_dataset$BusinessTravel)
labels(Integer_dataset$BusinessTravel)
levels(Integer_dataset$BusinessTravel)
temp <- data.frame(model.matrix(~ BusinessTravel - 1, data = Integer_dataset))
Integer_dataset <- data.frame(Integer_dataset, temp[-1])
names(Integer_dataset)
names(Integer_dataset)
names(Integer_dataset)
temp <- data.frame(model.matrix(~ Department - 1, data = Integer_dataset))
Integer_dataset <- data.frame(Integer_dataset, temp[-1])
temp <- data.frame(model.matrix(~ EducationField - 1, data = Integer_dataset))
Integer_dataset <- data.frame(Integer_dataset, temp[-1])
temp <- data.frame(model.matrix(~ Gender - 1, data = Integer_dataset))
Integer_dataset <- data.frame(Integer_dataset, temp[-1])
temp <- data.frame(model.matrix(~ JobRole - 1, data = Integer_dataset))
Integer_dataset <- data.frame(Integer_dataset, temp[-1])
temp <- data.frame(model.matrix(~ MaritalStatus - 1, data = Integer_dataset))
Integer_dataset <- data.frame(Integer_dataset, temp[-1])
temp <- data.frame(model.matrix(~ OverTime - 1, data = Integer_dataset))
Integer_dataset <- data.frame(Integer_dataset, temp[-1])
names(Integer_dataset)
Integer_dataset =Integer_dataset[,-c(25:31)]
names(Integer_dataset)
Integer_dataset$Attrition = as.numeric(as.character(factor(Integer_dataset$Attrition,
levels = c("No","Yes"),
labels = c(0,1))))
which(sapply(Integer_dataset, class) == "factor")
require(caret)
set.seed(123)
split_vector = sample.split(Integer_dataset$Attrition,SplitRatio = 0.7)
dev_data_int = subset(Integer_dataset, split_vector ==T)
hold_data_int = subset(Integer_dataset, split_vector ==F)
for(i in 1:45){
if(i!=24){
dev_data_int[i] = scale(dev_data_int[i])
}
}
require(neuralnet)
n = names(dev_data_int)
long_formula = as.formula(paste("Attrition ~", paste(n[!n %in% "Attrition"], collapse = " + ")))
set.seed(123)
NN_model_int = neuralnet(formula = long_formula,
data = dev_data_int,
hidden = 10,
err.fct = "sse",
linear.output = FALSE,
lifesign = "full",
lifesign.step = 1,
threshold = 0.01,
stepmax = 4000)
plot(NN_model_int)
dev_NN_pred = NN_model_int$net.result[[1]]
dev_df = data.frame(dev_NN_pred,dev_data_int$Attrition)
Dev_Original$NN_prob =dev_NN_pred
dev_NN_pred = ifelse(dev_NN_pred>=0.5,1,0)
table = addmargins(table(dev_data_int$Attrition,dev_NN_pred)) # ~98.4%
table
dev_NN_acc = (table[1]+table[5])/table[9]
dev_NN_acc
for(i in 1:45){
if(i!=24){
hold_data_int[i] = scale(hold_data_int[i])
}
}
holdout_NN_pred = compute(NN_model_int,hold_data_int[,-24])
holdout_NN_pred = holdout_NN_pred$net.result
hold_df = data.frame(holdout_NN_pred,hold_data_int$Attrition)
HoldOut_Original$NN_Pred = holdout_NN_pred
holdout_NN_pred = ifelse(holdout_NN_pred>=0.5,1,0)
table =addmargins(table(hold_data_int$Attrition,holdout_NN_pred)) # ~94.5
table
hold_NN_acc = (table[1]+table[5])/table[9]
hold_NN_acc
table
hold_NN_acc
dev_NN_pred = NN_model_int$net.result[[1]]
dev_df = data.frame(dev_NN_pred,dev_data_int$Attrition)
dev_NN_pred = ifelse(dev_NN_pred>=0.5,1,0)
Dev_Original$NN_prob =dev_NN_pred
table
table = addmargins(table(dev_data_int$Attrition,dev_NN_pred)) # ~98.4%
dev_NN_acc = (table[1]+table[5])/table[9]
dev_NN_acc
table
dev_NN_acc
hold_NN_acc
Dev_Original$Attrition
Dev_Original$Attrition = ifelse(Dev_Original$Attrition=="No",0,1)
Dev_Original$RF_Class = ifelse(Dev_data$RF_class=="No",0,1)
Dev_Original$NN_Class = dev_NN_pred
Dev_data$RF_clas
Dev_data$Attrition_Numeric = ifelse(Dev_data$Attrition=="No",0,1)
Dev_data_Prob = predict(RF_model,newdata = Dev_data, type='prob')
Dev_data_class =predict(RF_model,newdata = Dev_data, type='class')
Dev_data$RF_prob =Dev_data_Prob[,2]
Dev_data$decile = decile(Dev_data_Prob[,2])
Dev_data$RF_class = Dev_data_class
Dev_RF_Ranking = Ranking(data.table((Dev_data)))
Dev_Original$RF_Class = ifelse(Dev_data$RF_class=="No",0,1)
Dev_Original$NN_Class = dev_NN_pred
Dev_Original$Ensemble_prod = (Dev_Original$RF_Prob + Dev_Original$NN_prob)/2
Dev_Original$Class = ifelse(Dev_Original$Ensemble_prod>=0.3,1,0)
table =addmargins(table(Dev_Original$Attrition,Dev_Original$Class)) # 99.8 %
table
dev_Ensemble_acc = (table[1]+table[5])/table[9]
dev_Ensemble_acc
table
dev_Ensemble_acc
HoldOut_Original$Attrition = ifelse(HoldOut_Original$Attrition=="No",0,1)
HoldOut_Original$RF_Class = ifelse(HoldOut_Original$RF_Class=="No",0,1)
HoldOut_Original$NN_Class = holdout_NN_pred
HoldOut_Original$Ensemble_prod = (HoldOut_Original$RF_prob+HoldOut_Original$NN_Pred)/2
HoldOut_Original$Class = ifelse(HoldOut_Original$Ensemble_prod>=0.3,1,0)
table =addmargins(table(HoldOut_Original$Attrition,HoldOut_Original$Class)) # ~96.03
table
hold_Ensemble_acc = (table[1]+table[5])/table[9]
hold_Ensemble_acc
NN_model_int$act.fct()
NN_model_int$act.fct
paste0('plots/',name)
data_set = read.csv('HR_Employee_Attrition_Data.csv', header = T)
table(sapply(data_set,class))
factor_feildIDs=which(sapply(data_set, class) == "factor")
integer_feildIDs=which(sapply(data_set, class) == "integer")
library(caTools)
set.seed(123)
split_vector = sample.split(data_set$Attrition,SplitRatio = 0.7)
Dev_Original = subset(data_set, split_vector==T)
HoldOut_Original = subset(data_set, split_vector ==F)
Dev_data = Dev_Original
HoldOut_data = HoldOut_Original
require(ggplot2)
for( i in factor_feildIDs){
name = paste(names(Dev_data[i]),'.png', sep = '')
png(filename =paste0('plots/',name), width = 800, height = 600, units = 'px')
print(ggplot( Dev_data,
aes(x=Dev_data[,i],
fill =Dev_data$Attrition))+
xlab(names(Dev_data[i]))+
ylab('Frequency')+
geom_bar(position = 'dodge')+
guides(fill = guide_legend('Attrition')))
dev.off()
print.noquote(names(Dev_data[i]))
print.noquote(summary(Dev_data[,i]))
}
getwd()
for( i in factor_feildIDs){
name = paste(names(Dev_data[i]),'.png', sep = '')
png(filename =paste0('plots/',name), width = 800, height = 600, units = 'px')
print(ggplot( Dev_data,
aes(x=Dev_data[,i],
fill =Dev_data$Attrition))+
xlab(names(Dev_data[i]))+
ylab('Frequency')+
geom_bar(position = 'dodge')+
guides(fill = guide_legend('Attrition')))
dev.off()
print.noquote(names(Dev_data[i]))
print.noquote(summary(Dev_data[,i]))
}
sum(ifelse(data_set$Attrition=="No",0,1))
nrow(data_set)
474/2940
NN_model_int$net.result[[1]]
View(dev_df)
sum(dev_df$dev_data_int.Attrition)
RF_model
RF_model$forest
data_set$Attrition
table(data_set$Attrition)
table(Dev_data$Attrition)
table(test$Attrition)
table(HoldOut_data$Attrition)
library(caTools)
require(ggplot2)
require(gclus)
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  5000,  # large number because we want to build as many trees as possible
mtry =  6,
nodesize = 40)
library(randomForest)
set.seed(123)
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  5000,  # large number because we want to build as many trees as possible
mtry =  6,
nodesize = 40)
RF_model
plot(RF_model, main = "High number of trees vs OOB error")
set.seed(123)
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  500,
mtry =  6,
nodesize = 40)
RF_model
plot(RF_model, main = "Adjusted tree number vs OOB error")
set.seed(321)
tuned_RF_model = tuneRF(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
mtryStart = 2,
stepFactor = 1.5,
improve = 0.001,
ntreeTry = 500,
nodesize = 40,
doBest = T, trace = T, plot = T,importance = T)
RF_model = randomForest(x = Dev_data[-2],
y = Dev_data$Attrition,
data_set = Dev_data,
ntree =  500,
mtry =  19,
nodesize = 2)
RF_model
plot(RF_model)
RF_model$importance
RF_model$importanceSD
require(foreign)
setwd("~/GitHub/Projects/IB-ICE")
data = read.spss(file = 'IB ICE.sav',header=T)
?read.spss
data = read.spss(file = 'IB ICE.sav',header=T,to.data.frame = T)
View(data)
names(data)
cor(data[2:4])
require(psych)
principal()
?principal
L = principal(data[2:4],nfactors = 1)
L
L$loadings
L$r.scores
L$scores
setwd("C:/Users/ravin/Downloads")
require(readxl)
data = read_excel("Credit Default.xlsx",header = T)
data = read_excel("Credit Default.xlsx")
require(ggplot2)
require(dplyr)
glimpse(data)
summary(data)
require(foreign)
require(foreign)
require(foreign)
setwd("~/GitHub/Projects/IB-ICE")
data = read.spss('IB ICE.sav')
?read.spss
data = read.spss('IB ICE.sav',to.data.frame = T)
names(data)
data = read.spss('IB ICE.sav',to.data.frame = T)
names(data)
H6a_Model = lm(IBProp~Light_A,IBT_A,IBT_A*Light_A,data = data)
summary(H6a_Model)
H6a_Model = lm(IBProp~Light_A+IBT_A+IBT_A*Light_A,data = data)
summary(H6a_Model)
data$Light_A_1 = as.factor(ifelse(data$Light_A_1 %in% c(1,2,3),1,
ifelse(data$Light_A_1 %in% c(4,5),2,0)))
data$Light_A_1 = as.factor(ifelse(data$Light_A %in% c(1,2,3),1,
ifelse(data$Light_A %in% c(4,5),2,0)))
summary(data$Light_A_1)
data$IBT_A_1 = as.factor(ifelse(data$IBT_A %in% c(1,2,3),1,
ifelse(data$IBT_A %in% c(4,5),2,0)))
summary(data$IBT_A)
summary(data$IBT_A_10)
summary(data$IBT_A_1)
H6a_Model = lm(IBProp~Light_A_1+IBT_A_1+IBT_A_1*Light_A_1,data = data)
summary(H6a_Model)
H6a_Model = lm(IBProp~Light_A_1+IBT_A_1,data = data)
summary(H6a_Model)
