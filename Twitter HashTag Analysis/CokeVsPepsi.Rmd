---
title: "Coke vs Pepsi Twitter sentiment analysis"
author: "Ravindranadh"
date: "21st September 2017"
output: pdf_document
---

###1.Introduction
We focused on fetching the tweets with `coke` and `Pepsi` from twitter and analyse their sentiments.

Following are the necesssary libraries that are needed.
```{r message=FALSE,warning=FALSE}
if (Sys.getenv("JAVA_HOME")!="") Sys.setenv(JAVA_HOME="")
require(twitteR)
require(tm)
require(stringr)
require(qdap)
require(ggplot2)
require(wordcloud)
require(topicmodels)
require(tidytext)
require(dplyr)
require(plotrix)
require(ggthemes)
```

###2.Data Fetching
* Define your twitter authentication details (this part of code is hidden)
```{r echo=FALSE}
  consumerkey = "MTfL0uv6oBbtVBa3dPuR4PS51"
  consumersecret = "T480vrOtvSK1XxGcPp20SdRoW99by3EGVvAapzyq8io0uH6lUh"
  accesstoken = "191958252-uOisKMkvWHWmiTRQnf9d6XMww5wtZVtox1ShcjMm"
  accesssecret = "9kTTYtORX4KnXk9SG4R9bQ1PpmQyBYEwmfvDksTh6Wht0"
```

* Establish a connect with twitter developer API by passing the authentication details to `setup_twitter_oauth` function.
* Pull recent 5,000 tweets of each search
* Store the tweets in a dataframe and convert it to corpus.
```{r message=FALSE, results='hide',warning=FALSE}
setup_twitter_oauth(consumerkey,consumersecret,accesstoken,accesssecret)
CocaCola_TweetsList= searchTwitter(searchString ='Coke',n=5000 , lang = 'en') 
Pepsi_TweetsList= searchTwitter(searchString ='Pepsi',n=5000 , lang = 'en') 

CocaCola_DF = twListToDF(CocaCola_TweetsList)
Pepsi_DF = twListToDF(Pepsi_TweetsList)

CocaCola_DF$createdDate = as.Date(CocaCola_DF$created,format = "%d-%m-%Y")
Pepsi_DF$createdDate = as.Date(Pepsi_DF$created,format = "%d-%m-%Y")

CocaCola_Tweets = as.character(CocaCola_DF$text)
CocaCola_Corpus = Corpus(VectorSource(CocaCola_Tweets))

Pepsi_Tweets = as.character(Pepsi_DF$text)
Pepsi_Corpus = Corpus(VectorSource(Pepsi_Tweets))
```
```{r echo = FALSE}
write.csv(CocaCola_DF,'CocaCola_DF.csv')
write.csv(Pepsi_DF,'Pepsi_DF.csv')

```
```{r echo=FALSE}
write.csv(CocaCola_DF,'CocaColaTweets.csv')
write.csv(Pepsi_DF,'PepsiTweets.csv')
```
###3.Data Cleaning
* The corpus is subjected to cleaning by removing the `usernames` that are followed by **@**,
* `URLs` are removed.
* `Pure Numbers` i.e like 54 but not iphone8 (aplha-numeric), are removed.
* `Puctuations & whitespaces` are removed.
* Entire text is converted into `lower case`.
* `Abbrevations` are replaced.
* All the words are subjected to `stemming`.
* `Stopwords` are removed.
```{r results='hide',message=FALSE,warning=FALSE}
removeUsernameInRT <- function(x) str_replace_all(x,"(?<=@)[^\\s:]+",'')
CocaCola_Corpus = tm_map(CocaCola_Corpus, content_transformer(removeUsernameInRT))
Pepsi_Corpus = tm_map(Pepsi_Corpus, content_transformer(removeUsernameInRT))

removeURL <- function(x) gsub("http[^[:space:]]*", "", x)
CocaCola_Corpus = tm_map(CocaCola_Corpus, content_transformer(removeURL))
Pepsi_Corpus = tm_map(Pepsi_Corpus, content_transformer(removeURL))

removeCompleteNumbers <- function(x) str_replace_all(x,'(?<=[:blank:])[0-9]+(?=[:blank:])', '')
CocaCola_Corpus = tm_map(CocaCola_Corpus, content_transformer(removeCompleteNumbers))
Pepsi_Corpus = tm_map(Pepsi_Corpus, content_transformer(removeCompleteNumbers))

CocaCola_Corpus = tm_map(CocaCola_Corpus,removePunctuation)
Pepsi_Corpus = tm_map(Pepsi_Corpus,removePunctuation)
removeSingle <- function(x) gsub(" . ", " ", x)   
CocaCola_Corpus = tm_map(CocaCola_Corpus, content_transformer(removeSingle))
CocaCola_Corpus = tm_map(CocaCola_Corpus,stripWhitespace)
CocaCola_Corpus = tm_map(CocaCola_Corpus,content_transformer(tolower))
CocaCola_Corpus = tm_map(CocaCola_Corpus, content_transformer(replace_abbreviation))
Pepsi_Corpus = tm_map(Pepsi_Corpus, content_transformer(removeSingle))
Pepsi_Corpus = tm_map(Pepsi_Corpus,stripWhitespace)
Pepsi_Corpus = tm_map(Pepsi_Corpus,content_transformer(tolower))
Pepsi_Corpus = tm_map(Pepsi_Corpus, content_transformer(replace_abbreviation))

CocaCola_Corpus_Filtered = CocaCola_Corpus
CocaCola_Corpus = tm_map(CocaCola_Corpus, stemDocument,language = 'english')

Pepsi_Corpus_Filtered = Pepsi_Corpus
Pepsi_Corpus = tm_map(Pepsi_Corpus, stemDocument,language = 'english')

stemCompletionuserDefined <- function(x,dictionary) {
  x = unlist(strsplit(as.character(x)," "))
  x = x[x !=""]
  x = stemCompletion(x, dictionary = dictionary)
  x = paste(x, sep="", collapse=" ")
  PlainTextDocument(stripWhitespace(x))
}
CocaCola_Corpus = lapply(CocaCola_Corpus, stemCompletionuserDefined, dictionary=CocaCola_Corpus_Filtered)
Pepsi_Corpus = lapply(Pepsi_Corpus, stemCompletionuserDefined, dictionary=Pepsi_Corpus_Filtered)

temp = character()
for(i in 1: nrow(CocaCola_DF)){
  temp[i] = CocaCola_Corpus[[i]]$content
}
temp_df = data.frame(text = temp, stringsAsFactors = F)
CocaCola_Corpus = Corpus(VectorSource(temp_df$text))
CocaCola_Corpus = tm_map(CocaCola_Corpus, 
                       removeWords,c(stopwords('en'),'rt','cocacola','coke','drink'))
temp1 = character()
for(i in 1: nrow(Pepsi_DF)){
  temp1[i] = Pepsi_Corpus[[i]]$content
}
temp_df1 = data.frame(text = temp1, stringsAsFactors = F)
Pepsi_Corpus = Corpus(VectorSource(temp_df1$text))
Pepsi_Corpus = tm_map(Pepsi_Corpus, 
                         removeWords,c(stopwords('en'),'rt','pepsi','drink'))
rm(list = c('temp1','temp_df1','temp_df','temp'))
```

###4.Word Frequency Analysis
* Convert the corpus into `TermDocumentMatrix`.
* Calculate the frequency count of each word and create a dataframe of words & their frequencies.
```{r results='hide',message=FALSE,warning=FALSE}
CocaCola_Corpus_TDM = TermDocumentMatrix(CocaCola_Corpus)
CocaCola_Corpus_TDM_M = as.matrix(CocaCola_Corpus_TDM)
CocaCola_TermFrequency = rowSums(CocaCola_Corpus_TDM_M)
CocaCola_TermFrequency = sort(CocaCola_TermFrequency,decreasing =T)
Pepsi_Corpus_TDM = TermDocumentMatrix(Pepsi_Corpus)
Pepsi_Corpus_TDM_M = as.matrix(Pepsi_Corpus_TDM)
Pepsi_TermFrequency = rowSums(Pepsi_Corpus_TDM_M)
Pepsi_TermFrequency = sort(Pepsi_TermFrequency,decreasing =T)

Frequency_DF = data.frame(term = names(CocaCola_TermFrequency), 
                           freq= CocaCola_TermFrequency,
                           brand = 'CocaCola')
Frequency_DF = rbind(Frequency_DF,data.frame(term = names(Pepsi_TermFrequency), 
                                             freq= Pepsi_TermFrequency,
                                             brand = 'Pepsi') )
```

Following is the chart displaying the most used 25 words and their frequencies.
```{r}
Frequency_DF %>%
  top_n(25,freq) %>%
ggplot(aes(reorder(term, freq),freq,fill= brand)) +
  scale_fill_brewer(palette="Set1")+
  geom_bar(stat = "identity") + 
  coord_flip() +
  labs(list(title="Term Frequency Chart", x="Top 25 Terms", y="Term Counts")) 
```

Following the sample spare matrix representing the words live & people present in the frst few tweets
```{r}
index = which(dimnames(CocaCola_Corpus_TDM)$Terms %in% c("healthier", "dont"))
as.matrix(CocaCola_Corpus_TDM[index,1:50])
index = which(dimnames(Pepsi_Corpus_TDM)$Terms %in% c("best",'coke'))
as.matrix(Pepsi_Corpus_TDM[index,1:50])
```

Following is the word cloud consisting the most frequently used words
```{r warning=FALSE}
pal = brewer.pal(6, "Reds")
pal = pal[2:6]
wordcloud(words = names(CocaCola_TermFrequency), 
          freq = CocaCola_TermFrequency, 
          min.freq = 10, 
          random.order = F, 
          colors = pal, 
          max.words = 500)
pal = brewer.pal(7, "Blues")
pal = pal[4:7]
wordcloud(words = names(Pepsi_TermFrequency), 
          freq = Pepsi_TermFrequency, 
          min.freq = 10, 
          random.order = F, 
          colors = pal, 
          max.words = 500)
```

###5.Word Associations
Here we tried to find associations of Pepsi tweets with the word `best` and cocacola tweets with `dont`.
```{r results= 'hide', warning=FALSE,message=FALSE}
Pepsi_Associations = findAssocs(Pepsi_Corpus_TDM,terms ='best',corlimit=0.05)
Pepsi_Associations
Pepsi_Associations_df = list_vect2df(Pepsi_Associations)[, 2:3]
CocaCola_Associations = findAssocs(CocaCola_Corpus_TDM,terms ='dont',corlimit=0.2)
CocaCola_Associations
CocaCola_Associations_df = list_vect2df(CocaCola_Associations)[, 2:3]
```

Following are the various maps showing the correlation between the choosen word and all the tweets of repective search.
```{r warning=FALSE,error=FALSE}
ggplot(Pepsi_Associations_df, aes(y = Pepsi_Associations_df[, 1])) + 
  geom_point(aes(x = Pepsi_Associations_df[, 2],colour = Pepsi_Associations_df[, 2],
                 size = Pepsi_Associations_df[, 2] ), 
             data = Pepsi_Associations_df) + 
  theme_gdocs()+
  scale_color_continuous(high = '#18069A',low = "#8985A3")+
  guides(colour=FALSE,size =F)+
  xlab('Correlation')+ylab('Words')+ggtitle('Pepsi tweets Association with "BEST" ')
colnames(Pepsi_Associations_df) = c('Words','Corr')
qheat(Pepsi_Associations_df, values=TRUE, high="blue",
      digits=2, plot = FALSE) +
  coord_flip()+guides(fill=F,ylab=F)+
  xlab('Words')+ggtitle('Pepsi tweets HeatMap with "BEST"')
ggplot(CocaCola_Associations_df, aes(y = CocaCola_Associations_df[, 1])) + 
  geom_point(aes(x = CocaCola_Associations_df[, 2],colour = CocaCola_Associations_df[, 2],
                 size = CocaCola_Associations_df[, 2] ), 
             data = CocaCola_Associations_df) + 
  theme_gdocs()+
  scale_color_continuous(high = '#C40315',low = "#DE6C76")+
  guides(colour=FALSE,size =F)+
  xlab('Correlation')+ylab('Words')+ggtitle('CocaCola tweets Association with "dont" ')
colnames(CocaCola_Associations_df) = c('Words','Corr')
qheat(CocaCola_Associations_df, values=TRUE, high="red",
      digits=2, plot = FALSE) +
  coord_flip()+guides(fill=F,ylab=F)+
  xlab('Words')+ggtitle('CocaCola tweets HeatMap with "dont"')
```

###6.Topic Modeling 
Here we found top 5 discussed topics and their words
```{r warning=FALSE,error=FALSE}
CocaCola_Corpus_DTM <- as.DocumentTermMatrix(CocaCola_Corpus_TDM)
CrowTotals <- apply(CocaCola_Corpus_DTM , 1, sum)
CNullDocs <- CocaCola_Corpus_DTM[CrowTotals==0, ]
CocaCola_Corpus_DTM   <- CocaCola_Corpus_DTM[CrowTotals> 0, ]
if (length(CNullDocs$dimnames$Docs) > 0) {
  CocaCola_DF <- CocaCola_DF[-as.numeric(CNullDocs$dimnames$Docs),]
}
Clda <- LDA(CocaCola_Corpus_DTM, k = 5) 
Cterm <- terms(Clda, 5) 
Cterm
Ctopics<- topics(Clda)
Ctopics_df<- data.frame(date=(CocaCola_DF$created), topic = Ctopics)
X = cut(as.numeric(strftime(Ctopics_df$date, format="%H")),c(0,6,12,18,24))
levels(X) = c('night','morning','noon','evening')
qplot(X,..count.., data=Ctopics_df,
      geom ="density",
      fill= Cterm[topic],position="stack",
      xlab = 'Tweets Time', ylab='Count',main = 'Coca-Cola Topic Density')

Pepsi_Corpus_DTM <- as.DocumentTermMatrix(Pepsi_Corpus_TDM)
ProwTotals <- apply(Pepsi_Corpus_DTM , 1, sum)
PNullDocs <- Pepsi_Corpus_DTM[ProwTotals==0, ]
Pepsi_Corpus_DTM   <- Pepsi_Corpus_DTM[ProwTotals> 0, ]
if (length(PNullDocs$dimnames$Docs) > 0) {
  Pepsi_DF <- Pepsi_DF[-as.numeric(PNullDocs$dimnames$Docs),]
}
Plda <- LDA(Pepsi_Corpus_DTM, k = 5) 
Pterm <- terms(Plda, 5) 
Pterm
Ptopics<- topics(Plda)
Ptopics_df<- data.frame(date=(Pepsi_DF$created), topic = Ptopics)
X = cut(as.numeric(strftime(Ptopics_df$date, format="%H")),c(0,6,12,18,24))
levels(X) = c('night','morning','noon','evening')
qplot(X,..count.., data=Ptopics_df,
      geom ="density",
      fill= Pterm[topic],position="stack",
      xlab = 'Tweets Time', ylab='Count',main = 'Pepsi Topic Density')
```

###7.Sentiment Analysis 
Here we tried to find the positive and negative sentiment words and various emotional sentiment words
* Took the common words from `bing` lexicon to get the +ve or -ve sentiment details for each word.
* Applied `afinn` lexicon on to the above result to get the sentiment scores for each word.
```{r results='hide', warning=FALSE}
colnames(Frequency_DF) = c('word','freq','brand')
sentiment_df = Frequency_DF %>% 
  inner_join(get_sentiments('bing'), by='word')
sentiment_df = sentiment_df %>%
  inner_join(get_sentiments('afinn'),by='word') 
```

Following is the graph showing the top used words and their +/- Sentiment
```{r warning=FALSE,error=FALSE}
sentiment_df %>%
  top_n(25,freq) %>%
  mutate(x1 = reorder(word,freq),
         y1 = ifelse(sentiment=='positive',freq,-freq)) %>%
  ggplot(aes(x=x1, y= y1, fill = brand)) +
  scale_fill_brewer(palette="Set1")+
  geom_col(stat='identity') +
  coord_flip()+
  facet_wrap(~sentiment, scales = "free_x")+
  ggtitle('Lexicon based word frequency')+
  xlab('Words')+ylab('Frequency')
```

Here we tried the same but with regards to various emotional sentiments
```{r warning=FALSE,error=FALSE}
Emotion_sentiment_df = Frequency_DF %>% 
  inner_join(get_sentiments('nrc'), by='word')
Emotion_sentiment_df %>%
  group_by(sentiment) %>%
  top_n(10,freq) %>%
  ungroup() %>%
  mutate(word = reorder(word, freq)) %>%
  ggplot(aes(x = word, y = freq , fill  = brand)) +
  scale_fill_brewer(palette="Set1")+
  geom_col(show.legend = T) +
  facet_wrap(~ sentiment, scales = "free") +
  coord_flip()+
  ggtitle('Emotion based word frequency')+
  xlab('Words')+ylab('Frequency')

```
